{"cells":[{"cell_type":"markdown","id":"7cce1c38","metadata":{"id":"7cce1c38"},"source":["# Explore here - Problem Statement | Background\n"]},{"cell_type":"markdown","id":"b5c318ca","metadata":{"id":"b5c318ca"},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":null,"id":"f3b560e4","metadata":{"id":"f3b560e4"},"outputs":[],"source":["import os\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras.preprocessing import image"]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOq_VlZecG8a","executionInfo":{"status":"ok","timestamp":1707256997814,"user_tz":300,"elapsed":5539,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"cb8b2bb8-bd9a-4d9a-bbbf-3dcde9a299d9"},"id":"KOq_VlZecG8a","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.0\n"]}]},{"cell_type":"code","source":["pip install --upgrade tensorflow\n","pip install --upgrade keras"],"metadata":{"id":"3rOLS6HtcQMC"},"id":"3rOLS6HtcQMC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGfMCdX12HCz","executionInfo":{"status":"ok","timestamp":1707423682710,"user_tz":300,"elapsed":22354,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"4307ea58-9dd4-4e52-d2d2-7a4e18b212f6"},"id":"uGfMCdX12HCz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"6b8e1571","metadata":{"id":"6b8e1571"},"source":["### Step 1: Loading the images from the local folder"]},{"cell_type":"code","source":["# Now, let's check if the directories exist\n","import os\n","\n","train_dir = '/content/drive/MyDrive/Colab _Notebooks/4Geeks/Unsupervised/Image_classification/train'\n","test_dir = '/content/drive/MyDrive/Colab _Notebooks/4Geeks/Unsupervised/Image_classification/test/test1'\n","#'/content/drive/MyDrive/Colab _Notebooks/4Geeks/Unsupervised/Image_classification/test'\n","# Check if the directories exist\n","train_dir_exists = os.path.isdir(train_dir)\n","test_dir_exists = os.path.isdir(test_dir)\n","\n","train_dir_exists, test_dir_exists"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YUIAUPg3lCX","executionInfo":{"status":"ok","timestamp":1707423877142,"user_tz":300,"elapsed":173,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"bb66f853-fa1c-4d13-e294-1fa9504bf049"},"id":"8YUIAUPg3lCX","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, True)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"zOg_H0lktwVI"},"id":"zOg_H0lktwVI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define image dimensions and batch size\n","img_width, img_height = 200, 200\n","batch_size = 10\n","\n","# Initialize ImageDataGenerator objects for training and test data with basic preprocessing\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Load and preprocess training data\n","print(\"Loading training data...\")\n","trdata = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary',  # or 'categorical' for multi-class\n","    shuffle=True\n",")\n","print(f\"Found {trdata.samples} images belonging to {trdata.num_classes} classes for training.\")"],"metadata":{"id":"Qky3IqO5YvEZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707423803412,"user_tz":300,"elapsed":86455,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"c3e8bea4-e9af-46ce-e7a5-e4480aea766f"},"id":"Qky3IqO5YvEZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading training data...\n","Found 24405 images belonging to 2 classes.\n","Found 24405 images belonging to 2 classes for training.\n"]}]},{"cell_type":"code","source":["# Verify and preprocess test data\n","print(\"\\nVerifying test directory...\")\n","if not os.path.exists(test_dir) or not os.listdir(test_dir):\n","    print(\"Test directory is missing or empty. Please check the path and contents.\")\n","else:\n","    # List first few files in the test directory to verify\n","    test_files = os.listdir(test_dir)\n","    print(\"First 5 files in test directory:\", test_files[:5])\n","\n","    # Check for image file extensions\n","    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n","    image_files = [file for file in test_files if any(file.lower().endswith(ext) for ext in image_extensions)]\n","    print(f\"Found {len(image_files)} image files in test directory.\")\n","\n","    if len(image_files) == 0:\n","        print(\"No supported image files found. Please check the formats and structure.\")\n","    else:\n","        # Adjusted section for loading test data without class subdirectories\n","        print(\"Supported image files found. Proceeding with loading test data...\")\n","        tsdata = test_datagen.flow_from_directory(\n","            test_dir,\n","            target_size=(img_width, img_height),\n","            batch_size=batch_size,\n","            class_mode=None,  # Set class_mode to None for unlabeled data\n","            shuffle=False\n",")\n","print(f\"Found {len(tsdata.filenames)} images for testing.\")"],"metadata":{"id":"sL3TIzqTYgUZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707423885524,"user_tz":300,"elapsed":4479,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"7a2f252a-e978-4212-ac59-070335997af7"},"id":"sL3TIzqTYgUZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Verifying test directory...\n","First 5 files in test directory: ['9053.jpg', '9070.jpg', '9056.jpg', '9069.jpg', '9063.jpg']\n","Found 12459 image files in test directory.\n","Supported image files found. Proceeding with loading test data...\n","Found 0 images belonging to 0 classes.\n","Found 0 images for testing.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cNR2_XbCYF-U"},"id":"cNR2_XbCYF-U","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","\n","# Define the CNN structure with improvements\n","model = Sequential()\n","# He initialization is specified by the 'kernel_initializer' parameter.\n","model.add(Conv2D(input_shape=(200, 200, 3), filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.25))  # Dropout layer to reduce overfitting\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(units=4096, activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(Dropout(0.5))  # Increased dropout for dense layer\n","model.add(Dense(units=4096, activation=\"relu\", kernel_initializer='he_uniform'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units=2, activation=\"softmax\"))\n","\n","# Compile the model with a revised learning rate and optimizer\n","model.compile(optimizer=Adam(learning_rate=0.0001),  # Reduced learning rate\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Model summary to check the structure and parameters\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"geG0Nsg8YGkO","executionInfo":{"status":"ok","timestamp":1707423896774,"user_tz":300,"elapsed":1815,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"09b07254-e151-45ca-a6fa-44a9e52c6057"},"id":"geG0Nsg8YGkO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 200, 200, 64)      1792      \n","                                                                 \n"," batch_normalization (Batch  (None, 200, 200, 64)      256       \n"," Normalization)                                                  \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 200, 200, 64)      36928     \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 200, 200, 64)      256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 100, 100, 64)      0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 100, 100, 64)      0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 100, 100, 128)     73856     \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 100, 100, 128)     512       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 100, 100, 128)     147584    \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 100, 100, 128)     512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 50, 50, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 50, 50, 128)       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 50, 50, 256)       295168    \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 50, 50, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 50, 50, 256)       590080    \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 50, 50, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 50, 50, 256)       590080    \n","                                                                 \n"," batch_normalization_6 (Bat  (None, 50, 50, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 25, 25, 256)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 25, 25, 256)       0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 25, 25, 512)       1180160   \n","                                                                 \n"," batch_normalization_7 (Bat  (None, 25, 25, 512)       2048      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 25, 25, 512)       2359808   \n","                                                                 \n"," batch_normalization_8 (Bat  (None, 25, 25, 512)       2048      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 25, 25, 512)       2359808   \n","                                                                 \n"," batch_normalization_9 (Bat  (None, 25, 25, 512)       2048      \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 12, 12, 512)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 12, 12, 512)       0         \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 12, 12, 512)       2359808   \n","                                                                 \n"," batch_normalization_10 (Ba  (None, 12, 12, 512)       2048      \n"," tchNormalization)                                               \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 12, 12, 512)       2359808   \n","                                                                 \n"," batch_normalization_11 (Ba  (None, 12, 12, 512)       2048      \n"," tchNormalization)                                               \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 12, 12, 512)       2359808   \n","                                                                 \n"," batch_normalization_12 (Ba  (None, 12, 12, 512)       2048      \n"," tchNormalization)                                               \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 6, 6, 512)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_4 (Dropout)         (None, 6, 6, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 18432)             0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              75501568  \n","                                                                 \n"," dropout_5 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dropout_6 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 8194      \n","                                                                 \n","=================================================================\n","Total params: 107022658 (408.26 MB)\n","Trainable params: 107014210 (408.23 MB)\n","Non-trainable params: 8448 (33.00 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oNvEUF9w-RsA"},"id":"oNvEUF9w-RsA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training the model\n","print(\"Starting training...\")\n","history = model.fit(trdata,\n","                    epochs=5,\n","                    validation_data=tsdata)  # Assuming tsdata is your test dataset used as validation here\n","\n","# Evaluating the model\n","print(\"Training completed.\")\n","print(\"Evaluating model...\")\n","# Since tsdata is unlabeled, direct evaluation might not be possible. Typically, you'd use model.predict(tsdata) and manually assess predictions."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SKanDU0-RvP","outputId":"7316bfc1-71dc-4894-caac-95cf006aff06","executionInfo":{"status":"ok","timestamp":1707430521274,"user_tz":300,"elapsed":6579005,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}}},"id":"9SKanDU0-RvP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training...\n","Epoch 1/5\n","2441/2441 [==============================] - 6222s 3s/step - loss: 2.1652 - accuracy: 0.6066\n","Epoch 2/5\n","2441/2441 [==============================] - 89s 37ms/step - loss: 0.6673 - accuracy: 0.6844\n","Epoch 3/5\n","2441/2441 [==============================] - 88s 36ms/step - loss: 0.5246 - accuracy: 0.7523\n","Epoch 4/5\n","2441/2441 [==============================] - 88s 36ms/step - loss: 0.4087 - accuracy: 0.8190\n","Epoch 5/5\n","2441/2441 [==============================] - 88s 36ms/step - loss: 0.2899 - accuracy: 0.8794\n","Training completed.\n","Evaluating model...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gw8sF5h_-RzU"},"id":"gw8sF5h_-RzU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Model  # Assuming 'model' is a Keras model\n","\n","\n","# Define the path where the model will be saved, including the subfolder\n","file_path = \"models/vgg16_1.h5\"\n","\n","# Check if the directory exists, and if not, create it\n","if not os.path.exists(os.path.dirname(file_path)):\n","    os.makedirs(os.path.dirname(file_path))\n","\n","# Save the model to the specified path using Keras' save function\n","model.save(file_path)\n","\n","print(f\"Model saved successfully to {file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqub6danQVZL","executionInfo":{"status":"ok","timestamp":1707432623909,"user_tz":300,"elapsed":2253,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"a58b11ad-95f9-4fad-bd74-9daa24400970"},"id":"iqub6danQVZL","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Model saved successfully to models/vgg16_1.h5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"UXOQ7YANQVcc"},"id":"UXOQ7YANQVcc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","checkpoint = ModelCheckpoint(\"/models/vgg16_1.h5\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\")\n","early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, verbose = 1, mode = \"auto\")\n","hist = model.fit(trdata, steps_per_epoch = 100, validation_data = tsdata, validation_steps = 10, epochs = 3, callbacks = [checkpoint, early])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YM3SVzYViAm0","executionInfo":{"status":"ok","timestamp":1707432640755,"user_tz":300,"elapsed":11179,"user":{"displayName":"Alfredo Castaneda","userId":"17593831257050815113"}},"outputId":"a7b6ca5e-d37b-45ca-de1b-eb0599076114"},"id":"YM3SVzYViAm0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"," 99/100 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 0.2556 - accuracy: 0.8950\n","Epoch 2/3\n","100/100 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9130"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 35ms/step - loss: 0.2084 - accuracy: 0.9130\n","Epoch 3/3\n"," 99/100 [============================>.] - ETA: 0s - loss: 0.1869 - accuracy: 0.9263"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 4s 37ms/step - loss: 0.1856 - accuracy: 0.9270\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"kw8zQeKl-R0-"},"id":"kw8zQeKl-R0-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pickle import dump\n","\n","# Define the path where the model will be saved, including the subfolder\n","file_path = \"models/vgg16_1.h5\"\n","\n","# Save the model to the specified path\n","dump(model, open(file_path, \"wb\"))"],"metadata":{"id":"yPBIUkRchg0o"},"id":"yPBIUkRchg0o","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LvBlx9pHhg3r"},"id":"LvBlx9pHhg3r","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[{"file_id":"1kvFgaFkSx_93oSx7oHD7VDkfwEEwVK5P","timestamp":1707255601757}],"gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}